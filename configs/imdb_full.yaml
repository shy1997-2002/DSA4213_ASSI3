model_name: distilbert-base-uncased
task: imdb
method: full
num_labels: 2
max_length: 256
batch_size: 16
eval_batch_size: 32
learning_rate: 2e-5
num_train_epochs: 3
output_dir: outputs/imdb_full
logging_steps: 100
evaluation_strategy: epoch
fp16: true
seed: 42
